# ğŸ§  LangChain Q&A Application

A simple **Q&A Application** using **FastAPI**, **LangChain**, and **OpenAI GPT-3.5 Turbo** for answering user queries. The frontend is built with **Streamlit** for an interactive UI.

---
## ğŸš€ Features
- ğŸ“Œ FastAPI-based backend to process user queries.
- ğŸ¤– OpenAI-powered responses via LangChain.
- ğŸ¨ Streamlit frontend for an interactive Q&A experience.
- ğŸ” Uses `.env` file to store API keys securely.

---
## Project Structure

```sh
langchain-qa-app/
â”‚â”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py  # Streamlit UI
â”‚â”€â”€ main.py      # FastAPI backend
â”‚â”€â”€ requirements.txt  # Project dependencies
â”‚â”€â”€ .env         # Environment variables
â”‚â”€â”€ README.md    # Project documentation
```

---
## Technologies Used
* **FastAPI** for backend API
* **Streamlit** for frontend UI
* **LangChain** for AI-based responses
* **OpenAI GPT-3.5-turbo** for answering questions

---
## ğŸ“Œ Prerequisites
Ensure you have the following installed on your system:
- **Python 3.13+**
- **pip** (Python package manager)

---
## ğŸ›  Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/haseebahmed49/langchain-qa-app.git
cd langchain-qa-app
```

### 2ï¸âƒ£ Create a Virtual Environment
```sh
python -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies
```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up Environment Variables
Create a `.env` file in the root directory and add your OpenAI API key:
```sh
echo "OPENAI_API_KEY=your_openai_api_key_here" > .env
```

---
## ğŸ–¥ Backend (FastAPI)

### ğŸ“Œ Start the FastAPI Server
Run the backend using:
```sh
uvicorn backend.main:app --reload
```
The API will be available at `http://127.0.0.1`.

### ğŸ“Œ API Endpoint
- **`POST /ask`** â†’ Accepts a JSON object `{ "question": "your question" }` and returns an AI-generated answer.

---
## ğŸ¨ Frontend (Streamlit)

### ğŸ“Œ Run the Streamlit App
```sh
streamlit run app.py
```

---
## ğŸ”„ How It Works
1. User inputs a question in the Streamlit app.
2. The frontend sends a request to the FastAPI backend (`/ask` endpoint).
3. FastAPI processes the request and queries OpenAI GPT-3.5 using LangChain.
4. The AI-generated answer is returned and displayed in the Streamlit app.

---
## ğŸ“œ License
This project is licensed under the MIT License.

---
## ğŸ“© Contact
For issues or suggestions, feel free to open an [issue](https://github.com/haseebahmed49/langchain-qa-app/issues) or reach out!
* Email: haseebahmed02@gmail.com
* LinkedIn/GitHub: /HaseebAhmed49

ğŸ’¡ **Happy Coding!** ğŸš€

